# Geometric Structure in Language Model Representations

This repository examines geometric properties of token and attention representations in large language models through three complementary perspectives:

- Hyperbolic embedding of semantic hierarchies  
- Curvature-aware graph structure induced by distances  
- Optimal transport alignment of distributed representations  

All computations are performed in the Poincar√© ball model:

- Embeds a semantic hierarchy into hyperbolic space  
- Constructs a distance-induced graph with curvature proxy  
- Aligns perturbed copies of the embeddings via Wasserstein barycenter  
